{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用前请确保 HM3D 的标签和配置对应的 `tar` 文件已经解压完成，但如果场景对应的 `tar` 文件过大，则无需解压，直接运行\n",
    "\n",
    "如果需要改变存储的格式，请随意修改 `save_sample()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"width\": 256,\n",
    "    \"height\": 256,\n",
    "    'T_per_sample': 100, # 每个场景中，随机产生多少个位置\n",
    "    'rotation_step': 360.0, # 在每个位置上，产生该值除 360 个样本，相邻两个样本间摄像机朝向相差该值；该值为 360 表示每个位置采一个样本\n",
    "\n",
    "    # 数据集位置\n",
    "    \"dataset\": \"../hm3d_train/\",\n",
    "    \"dataset_config\": \"../hm3d_train/hm3d_annotated_train_basis.scene_dataset_config.json\", # Configuration of the dataset\n",
    "    \"classes_json\": \"../rgbx/minival/classes.json\",\n",
    "\n",
    "\n",
    "    # 采样结果的储存位置\n",
    "    \"rgb_path\": \"../../../data/rgbx/train/rgb\",\n",
    "    \"depth_path\": \"../../../data/rgbx/train/depth\",\n",
    "    \"semantic_path\": \"../../../data/rgbx/train/label\",\n",
    "\n",
    "    \"sensor_height\": 1.5,  # 传感器的高度，单位：米\n",
    "    \"enable_physics\": False, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def save_sample(rgb_obs: np.ndarray, depth_obs: np.ndarray, semantic_obs: np.ndarray, rgb_path: str, depth_path: str, semantic_path: str):\n",
    "    rgb_img = Image.fromarray(rgb_obs, mode=\"RGBA\")\n",
    "    rgb_img.save(rgb_path)\n",
    "\n",
    "    np.save(depth_path, depth_obs)\n",
    "    np.save(semantic_path, semantic_obs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置完成后运行剩下的全部代码，即可在 `settings['rgb_path'/'depth_path'/'semantic_path']` 下找到采样后的 RGB/D/Semantic 图像。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主体部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_cfg, make_samples, display_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在单独场景中采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.perception.utils import ClassManager\n",
    "import habitat_sim\n",
    "def sample(scene_name, sim, T: int, rgb_path: str, depth_path: str, semantic_path: str, display: bool=False):\n",
    "    import random\n",
    "    import os\n",
    "    cm = ClassManager.from_sim(sim, settings['classes_json'])\n",
    "    paths = {'color': rgb_path, 'depth': depth_path, 'semantic': semantic_path}\n",
    "    for t in range(T):\n",
    "        pos = None\n",
    "        while pos is None or not sim.pathfinder.is_navigable(pos):\n",
    "            pos = sim.pathfinder.get_random_navigable_point()\n",
    "        rot = np.array(random.random() * 2 * np.pi)\n",
    "        orientation = np.quaternion(np.cos(rot / 2), 0, -1 * np.sin(rot / 2), 0)\n",
    "        # orientation = np.quaternion(1, 0, 0, 0)\n",
    "        state = habitat_sim.AgentState(position=pos, rotation=orientation, sensor_states=sim.get_agent(0).get_state().sensor_states)\n",
    "        sim.get_agent(0).set_state(state=state, reset_sensors=False)\n",
    "\n",
    "        for k in range(int(360 / settings['rotation_step'])):\n",
    "            obs = sim.step('turn_right')\n",
    "            if display:\n",
    "                (obs['color_sensor'], cm.instance_to_global(obs['semantic_sensor']), obs['depth_sensor'])\n",
    "            prefix = scene_name + \"_\" + f\"{pos}\".replace(' ','').replace('[', '').replace(']', '') + \"_\" + f\"{k}\"\n",
    "            save_sample(\n",
    "                obs['color_sensor'], obs['depth_sensor'], cm.instance_to_global(obs['semantic_sensor']), \n",
    "                os.path.join(rgb_path, prefix + \".png\"),\n",
    "                os.path.join(depth_path, prefix + \".npy\"),\n",
    "                os.path.join(semantic_path, prefix + \".npy\"),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_samples_for_scene(sim: habitat_sim.Simulator,scene_dir:str, scene_name:str=None):\n",
    "    sample(scene_name, sim, settings['T_per_sample'], settings['rgb_path'], settings['depth_path'], settings['semantic_path'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在所有场景中采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_samples(settings, make_samples_for_scene)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 21:12:53) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab258c8127595e7bcc65638ec3223783ec8b6f3f7de902030e2c0718ac7ad4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
